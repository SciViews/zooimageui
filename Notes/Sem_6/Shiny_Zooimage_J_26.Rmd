---
title: "Shiny_Zooimage_J_26"
output: html_document
---

Fichier de notes du jour 26, Lundi 07 Mars 2022.    Présentiel.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

=== Choses à faire update ===

1) Données sur le disque : Qu'est-ce qu'on peut faire avec l'app Shiny ? Accès des données ? Ailleurs sur le disque ? (vdd)
  => J'ai déjà beaucoup regardé à ça, et rien trouvé de spécial...

2) Golem => modularisation
  => J'ai déjà regardé au fonctionnement de ça également : Je sais comment faire à partir d'un nouveau projet.

3) Machine learning : classification
  => J'y ai également regardé un peu, les débuts de la modélisation.

4) Cahier des charges (définition la plus complète et détaillée de ce que le travail doit faire) \
- fonctionnalités (ex : traitements local / serveur) \
- implémentation (comment ça fonctionne) (ex : accès des données, ...) \
- interface (MOCK : ex, draw.io) \
- timing \
- tests/maintenances \

=============================


Pour reprendre dans mon apprentissage de la modélisation dans ZooImage : \
Certaines de ces commandes ne peuvent pas être exécutées directement dans le chunk car sinon elle ne s'appliquent pas au long terme. (les setups) (old_dir <- setwd(rootpath) principalement) \

```{r}
rootpath <- "/home/rstudio/shared/zooimage-ui/ZI_Tests/"

smps <- c("./data/Samples/MTPS.2004-10-20.V5.zidb",
          "./data/Samples/MTLG.2005-05-24.H1.zidb")
library(zooimage)

old_stringsAsFactors <- getOption("stringsAsFactors")
options(stringsAsFactors = TRUE)

old_dir <- setwd(rootpath)

train <- getTrain("./data/Training set")
train$Class <- factor(train$Class, levels = basename(attr(train, "path")) )

classif <- ZIClass(Class ~ ., train, method = "mlRforest", calc.vars = calcVars,
    ntree = 200, cv.k = 10) # Note than method, calc.vars & cv.k are default values
classif


```

Les derniers tests effectués à partir du manuel :

```{r}
names(train) # Original variables
names(traincalc <- calcVars(train)) # Variables as seen be classifier
```

Procédure de choix d'une variable, en se basant sur l'indice de Gini, calculé avec l'algorithme de forêt aléatoire, pour sélectionner seulement les prédicteur les plus discriminants.

```{r}
require(randomForest)
# Importance of the predictors
Imp <- classif$importance
varImpPlot(classif, n.var = nrow(Imp))
# Importance of preditor variables as measured by the mean decrease of the Gini index for the random forest classifier classif.
Threshold <- 30
abline(v = Threshold, lty = 2)
# Drop variables with low Gini decrease
VarsToDrop <- rownames(Imp)[Imp < Threshold]
```

La liste des prédicteurs que on veut utiliser dans Zooimage est spécifié dans l'option ZI.dropVars de cette manière :

```{r}
Imp <- classif$importance
Threshold <- 30
VarsToDrop <- rownames(Imp)[Imp < Threshold]
options(ZI.dropVars = VarsToDrop)
# Now, 'Min' is drop from the dataset
names(traincalc <- calcVars(train, drop.vars = VarsToDrop)) # ou getOption("ZI.dropVars")
```

Il faut faire attention que le options ne suffit pas. ici, il faut préciser dans le calcVars() l'option drop.vars = "" afin de préciser quelles variables calculées on souhaite éliminer. (soit en prenant les valeurs de VarsToDrop ou en allant chercher avec getOption()) \

Concrêtement, on pourrait remplacer la fonction calcVars afin qu'elle calcule d'autre variables qui nous intéresse, d'autre prédicteurs.

Une autre étape utile consiste à choisir des meilleurs paramètres pour l'algorithme de classification. Par exemple, pour "random forest" on peut changer le nombre d'arbres à utiliser. \

```{r}
plot(classif$err.rate[, "OOB"], type = "l", xlab = "trees", ylab = "Error")
abline(v = 200, lty = 2)
```

En fait dans ce cas, le résultat est pas très utile ni intéressant car on avait déjà set le nombre d'abres à 200. Mais l'idée est que si le nombre d'abres était 500 par exemple, on verrait que la courbe devient très linéaire à partir de 200. Donc on a gardé la valeur de 200 arbres. \




